import streamlit as st
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import StandardScaler
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score
import gzip
import pickle
import xgboost as xgb



# Mostrar la imagen solo en la p√°gina de inicio
st.title("An√°lisis de Detecci√≥n de Ocupaci√≥n")
st.write("Grupo: Yulisa Ortiz Giraldo y Juan Pablo Nore√±a Londo√±o")
if "image_displayed" not in st.session_state:
    st.image("image1.jpg", use_container_width=True)
    st.session_state["image_displayed"] = True  # Marcar que la imagen ya se mostr√≥

# Crear una tabla de contenido en la barra lateral
seccion = st.sidebar.radio("Tabla de Contenidos", 
                           ["Vista previa de los datos", 
                            "Informaci√≥n del dataset", 
                            "An√°lisis Descriptivo", 
                            "Mapa de calor de correlaciones", 
                            "Distribuci√≥n de la variable objetivo", 
                            "Boxplots", 
                            "Conclusi√≥n: Selecci√≥n del Mejor Modelo",  # Nueva ubicaci√≥n
                            "Modelo XGBoost",  # Nueva secci√≥n
                            "Modelo de redes neuronales"])

# Cargar los datos
def load_data():
    df_train = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatrain.csv")
    df_test = pd.read_csv("https://raw.githubusercontent.com/JuanPablo9999/Mineria_de_datos_streamlit/main/datatest.csv")
    df = pd.concat([df_train, df_test], axis=0)
    df.drop(columns=["id", "date"], inplace=True, errors='ignore')
    return df

df = load_data()

# Preprocesamiento
def preprocess_data(df):
    X = df.drop(columns=["Occupancy"], errors='ignore')
    y = df["Occupancy"]
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)
    return X_scaled, y, scaler

X, y, scaler = preprocess_data(df)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Mostrar contenido basado en la selecci√≥n
if seccion == "Vista previa de los datos":
    st.subheader("Vista previa de los datos")
    st.write(df.head())

elif seccion == "Informaci√≥n del dataset":
    st.subheader("Informaci√≥n del dataset")
    st.write(df.info())
    st.write("La base de datos seleccionada para el desarrollo de la aplicaci√≥n corresponde a un estudio dise√±ado para optimizar actividades de clasificaci√≥n binaria para determinar s√≠ una habitaci√≥n est√° ocupada o no. Dentro de sus caracter√≠sticas, se recopilan mediciones ambientales tales como la temperatura, la humedad del ambiente, la luz o nivel de luminosidad, y niveles de CO2, donde, con base a estas se determina s√≠ la habitaci√≥n est√° ocupada. La informaci√≥n de ocupaci√≥n se obtuvo mediante la obtenci√≥n de im√°genes capturadas por minuto, garantizando etiquetas precisas para la clasificaci√≥n. Este conjunto de datos resulta muy importante y √∫til para la investigaci√≥n basada en la detecci√≥n ambiental y el dise√±o de sistemas de edificios inteligentes seg√∫n sea el inter√©s del usuario.")
    st.write("La base cuenta con un total de 17.895 datos con un total de 8 variables, sin embargo, se utilizar√° una cantidad reducida de variables debido a que aquellas como ‚ÄúID‚Äù y ‚ÄúFecha‚Äù no aportan informaci√≥n relevante para la aplicaci√≥n de los temas anteriormente tratados.")
    st.write("El conjunto de datos fue obtenido del repositorio p√∫blico Kaggle, ampliamente utilizado en investigaciones relacionadas con sistemas inteligentes y monitoreo ambiental. La fuente original corresponde al trabajo disponible en el siguiente enlace: https://www.kaggle.com/datasets/pooriamst/occupancy-detection.")

elif seccion == "An√°lisis Descriptivo":
    st.subheader("Resumen de los datos")
    st.write(df.describe())
    st.subheader("Histograma de Temperature")
    # Temperatura
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Temperature"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Temperature')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Temperature')
    st.pyplot(fig)
    st.write("Del histograma anterior, se denota que la mayor√≠a de im√°genes tomadas de la habitaci√≥n captaron una temperatura de entre 20¬∞C y 21¬∞C, siendo una temperatura ambiente la que m√°s predomina en el conjunto de datos. Adem√°s, se observa que la temperatura m√≠nima registrada es de 19¬∞C y la m√°xima es un poco superior a 24¬∞C. Por tanto, en la habitaci√≥n no hay presencia de temperaturas que se consideren bajas o altas.")
    #  Humidity
    st.subheader("Histograma de Humidity")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Humidity"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Humidity')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Humidity')
    st.pyplot(fig)
    st.write("De la variable ‚ÄúHumidity‚Äù, se observa que la humedad se encuentra entre aproximadamente un 16% y un 40%. Para su interpretaci√≥n en este caso, se debe conocer cu√°les son los valores de humedad normales en una habitaci√≥n, para ello, la empresa Philips (sin fecha) en su publicaci√≥n ‚Äú¬øC√≥mo medir la humedad recomendada en casa?‚Äù afirma que la humedad ideal debe encontrarse entre 30% y 60% para la conservaci√≥n de los materiales de las paredes y el piso; por otra parte, en el blog Siber. (n.d.) mencionan que el ser humano puede estar en espacios con una humedad de 20% a 75%. Teniendo en cuenta lo anterior, se puede afirmar que la humedad en la mayor√≠a de los datos es adecuada para las personas, para los casos cuyo valor de humedad es menor a 20% no resulta ideal pero no deber√≠a ser un inconveniente significativo.")
    # HumidityRatio
    st.subheader("Histograma de HumidityRatio")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["HumidityRatio"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('HumidityRatio')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de HumidityRatio')
    st.pyplot(fig)
    st.write("Este histograma corresponde a la cantidad derivada de la temperatura y la humedad relativa dada en kilogramo de vapor de agua por kilogramo de aire, los valores se encuentran entre 0.002 kg vapor de agua/kg de aire hasta 0.0065 kg vapor de agua/ kg de aire aproximadamente. Seg√∫n la explicaci√≥n de la variable anterior, los resultados de la relaci√≥n se encuentran en un rango adecuado.")
    # Light
    st.subheader("Histograma de Light")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["Light"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('Light')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de Light')
    st.pyplot(fig)
    st.write("De la variable Light, se observa que en la gran mayor√≠a de los datos no hubo presencia de luz, no obstante, se denota el incremento en los valores cercanos a 500lux, esto indica que en estos casos s√≠ se hizo uso de la luz el√©ctrica en la habitaci√≥n debido al flujo luminoso provocado por el bombillo. Este podr√≠a ser un factor importante en la determinaci√≥n de s√≠ la habitaci√≥n est√° ocupada o no, pero esto se confirmar√° m√°s adelante en los resultados.")
    # CO2
    st.subheader("Histograma de CO2")
    fig, ax = plt.subplots(figsize=(8, 6))
    ax.hist(x=df["CO2"], bins=30, color='blue', edgecolor='black', alpha=0.7)
    ax.set_xlabel('CO2')
    ax.set_ylabel('Frecuencia')
    ax.set_title('Histograma de CO2')
    st.pyplot(fig)
    st.write("Para la variable de CO2, se observa que los niveles de CO2 dados en ppm (part√≠culas por mill√≥n) de aproximadamente 400 a 700pm son los m√°s presentes en el conjunto de datos. Se registran m√°s casos donde los niveles de CO2 son mucho mayores a los recurrentes, llegando hasta los 2000ppm. Para comprender la tolerancia de una persona hacia el CO2, la empresa Enectiva (2017) en su publicaci√≥n ‚ÄúEfectos de la concentraci√≥n de CO‚ÇÇ para la salud humana‚Äù expone que las habitaciones deben tener niveles de CO2 m√°ximo recomendado en 1200-1500ppm, a partir de este valor pueden presentarse efectos secundarios sobre las personas, como la fatiga y la p√©rdida de concentraci√≥n; a niveles mayores a los presentes en el histograma puede provocar aumento del ritmo card√≠aco, dificultades respiratorias, n√°useas, e inclusive la p√©rdida de la consciencia. Los niveles de CO2 pueden ser un indicativo clave para determinar s√≠ la habitaci√≥n est√° ocupada o no debido a la naturaleza del ser humano de expulsar di√≥xido de carbono ‚ÄúCO2‚Äù en su exhalaci√≥n, aunque debe tenerse en cuenta que un nivel elevado de CO2 puede deberse a razones diferentes del proceso de respiraci√≥n de la persona.")
    
elif seccion == "Distribuci√≥n de la variable objetivo":
    st.subheader("Distribuci√≥n de la variable objetivo")
    fig, ax = plt.subplots()
    sns.countplot(x=df["Occupancy"], ax=ax)
    st.pyplot(fig)
    st.write("De la variable respuesta ‚ÄúOccupancy‚Äù, se obtiene que en su mayor√≠a de casos se tiene como resultado que la habitaci√≥n no se encuentra ocupada, denotada con el valor de cero y por el valor 1 en el caso contrario. Se obtuvo que en el 78.9% de los casos la habitaci√≥n est√° vac√≠a, y en el 21.1% se encuentra ocupada.")

elif seccion == "Mapa de calor de correlaciones":
    st.subheader("Mapa de calor de correlaciones")
    st.write("Se plantea la matriz de correlaci√≥n de las variables mencionadas para verificar qu√© tan relacionadas se encuentran con la variable respuesta de ‚ÄúOccupancy‚Äù y as√≠ observar cu√°les tendr√≠an mayor incidencia en la toma de decisi√≥n:")
    fig, ax = plt.subplots(figsize=(10, 5))
    sns.heatmap(df.corr(), vmin=-1, vmax=1, cmap="coolwarm", annot=True, ax=ax)
    st.pyplot(fig)
    st.write("Seg√∫n la matriz, la variable que m√°s se correlaciona con la variable respuesta es la luz (‚ÄúLight‚Äù), pues es una determinante importante en la ocupaci√≥n de una habitaci√≥n; seguido de √©sta, se denotan las variables de temperatura y CO2, cuyas caracter√≠sticas se encuentran estrechamente relacionadas con la presencia de personas en un espacio. Por √∫ltimo, debe mencionarse que las variables relacionadas con la humedad presentan una muy baja correlaci√≥n con la ocupaci√≥n de una habitaci√≥n, esto debe tenerse en cuenta en la formulaci√≥n del modelo para la aplicaci√≥n y considerar s√≠ se eliminan estas variables dependiendo de los resultados que se obtengan.")

elif seccion == "Boxplots":
    st.subheader("Conjunto de boxplots")
    st.image("Boxplots.jpeg", use_container_width=True)
    st.write("""
    ### An√°lisis de Variables

    #### CO2 (Di√≥xido de carbono):
    - **Habitaci√≥n vac√≠a (rojo):** Niveles considerablemente m√°s bajos, con una mediana en torno a 500ppm.
    - **Habitaci√≥n ocupada (verde):** Niveles mucho m√°s altos, con una mediana cerca de 1000ppm.
    - El nivel de CO2 aumenta notablemente con la ocupaci√≥n, posiblemente debido a la respiraci√≥n de las personas.

    #### Humidity (Humedad):
    - **Habitaci√≥n vac√≠a (rojo):** Mediana ligeramente por encima de 25, con dispersi√≥n moderada.
    - **Habitaci√≥n ocupada (verde):** Mediana cerca de 30, con valores m√°s altos.
    - La ocupaci√≥n no parece variar mucho la humedad, en l√≠nea con la matriz de correlaciones.

    #### HumidityRatio (Proporci√≥n de humedad):
    - **Habitaci√≥n vac√≠a (rojo):** Valores concentrados alrededor de 0.0035.
    - **Habitaci√≥n ocupada (verde):** Valores ligeramente m√°s altos, alrededor de 0.004.
    - Aunque las diferencias no son grandes, la ocupaci√≥n est√° asociada con un peque√±o incremento en la proporci√≥n de humedad.

    #### Light (Luz):
    - **Habitaci√≥n vac√≠a (rojo):** Gran dispersi√≥n, con valores extremos muy altos.
    - **Habitaci√≥n ocupada (verde):** Valores m√°s bajos y concentrados.
    - La ocupaci√≥n 0 (habitaci√≥n vac√≠a) est√° asociada con niveles de luz m√°s altos y variables, posiblemente por la ausencia de personas que reduzcan el uso de iluminaci√≥n artificial.

    #### Temperature (Temperatura):
    - **Habitaci√≥n vac√≠a (rojo):** Mediana cerca de 20¬∞C, con dispersi√≥n moderada.
    - **Habitaci√≥n ocupada (verde):** Mediana ligeramente m√°s alta, alrededor de 22¬∞C.
    - La temperatura es m√°s alta con ocupaci√≥n, posiblemente por el calor generado por las personas o el uso de calefacci√≥n.

     #### Conclusi√≥n:
    La ocupaci√≥n tiene un impacto claro en **CO2, Light (luz) y Temperature (temperatura)**, aumentando sus valores en comparaci√≥n con la falta de ocupaci√≥n. En particular, la luz tiende a ser m√°s alta y variable cuando hay ocupaci√≥n. Otras variables como la humedad presentan cambios menores, pero no son significativos.
    """)

# Nueva secci√≥n: Conclusi√≥n sobre la selecci√≥n del mejor modelo
elif seccion == "Conclusi√≥n: Selecci√≥n del Mejor Modelo":
    st.subheader("Conclusi√≥n: Selecci√≥n del Mejor Modelo (XGBoost)")
    st.markdown("""
    Despu√©s de evaluar varios modelos de machine learning para la tarea de predecir la ocupaci√≥n de habitaciones, se determin√≥ que el **XGBoost Classifier** es el modelo m√°s adecuado para este problema. A continuaci√≥n, se detallan las razones por las que se seleccion√≥ este modelo y por qu√© los otros no fueron la mejor opci√≥n:

    #### Razones para elegir XGBoost:
    1. **Alto Rendimiento en Precisi√≥n y F1-Score**:
       - XGBoost demostr√≥ un rendimiento superior en t√©rminos de precisi√≥n y F1-Score, lo que indica que es capaz de predecir correctamente tanto las habitaciones ocupadas como las desocupadas. Esto es especialmente importante en problemas de clasificaci√≥n donde el equilibrio entre precisi√≥n y recall es crucial.

    2. **Manejo de Desequilibrio de Clases**:
       - En problemas donde las clases est√°n desequilibradas (por ejemplo, m√°s datos de habitaciones desocupadas que ocupadas), XGBoost es conocido por su capacidad para manejar este desequilibrio de manera efectiva, lo que lo hace m√°s robusto y confiable.

    3. **Interpretabilidad de las Caracter√≠sticas**:
       - XGBoost proporciona una clara interpretaci√≥n de la importancia de las caracter√≠sticas, lo que permite identificar qu√© variables (como el nivel de CO2, la luz o la humedad) son m√°s relevantes para la predicci√≥n. Esto es invaluable para entender el problema y tomar decisiones basadas en datos.

    4. **Eficiencia y Escalabilidad**:
       - XGBoost es un modelo altamente eficiente y escalable, lo que lo hace adecuado para conjuntos de datos m√°s grandes y complejos. Aunque en este caso el conjunto de datos no es extremadamente grande, su eficiencia asegura un entrenamiento r√°pido y un rendimiento √≥ptimo.

    5. **Robustez ante Overfitting**:
       - Gracias a sus t√©cnicas de regularizaci√≥n, XGBoost es menos propenso al sobreajuste (overfitting) en comparaci√≥n con otros modelos, lo que garantiza que el modelo generalice bien a nuevos datos.

    #### Razones por las que otros modelos no fueron seleccionados:
    - **Random Forest**: Aunque es un modelo potente, tiende a ser m√°s lento y menos eficiente en t√©rminos de memoria en comparaci√≥n con XGBoost. Adem√°s, XGBoost suele superar a Random Forest en t√©rminos de precisi√≥n y F1-Score en muchos casos.
    
    - **Decision Tree**: Es un modelo m√°s simple y propenso al overfitting, especialmente en conjuntos de datos m√°s complejos. No tiene la capacidad de regularizaci√≥n que tiene XGBoost, lo que lo hace menos confiable para generalizar.

    - **K-Nearest Neighbors (KNN)**: Aunque es un modelo intuitivo, KNN es computacionalmente costoso y no maneja bien el desequilibrio de clases. Adem√°s, no proporciona una interpretaci√≥n clara de la importancia de las caracter√≠sticas, lo que limita su utilidad en este contexto.

    - **Red Neuronal**: Aunque las redes neuronales pueden ser muy poderosas, requieren una gran cantidad de datos y ajustes hiperparam√©tricos para alcanzar su m√°ximo potencial. En este caso, el modelo secuencial utilizado es relativamente simple y no supera a XGBoost en t√©rminos de precisi√≥n o F1-Score.

    ### Conclusi√≥n Final:
    El **XGBoost Classifier** fue seleccionado como el mejor modelo debido a su alto rendimiento, capacidad para manejar el desequilibrio de clases, interpretabilidad de las caracter√≠sticas, eficiencia y robustez ante el overfitting. Estos factores lo convierten en la opci√≥n m√°s adecuada para la tarea de predecir la ocupaci√≥n de habitaciones, superando a otros modelos como Random Forest, Decision Tree, KNN y la red neuronal en este contexto espec√≠fico.
    """)
# Cargar el modelo XGBoost
def load_model(filename="xgb_model.pkl.gz"):
    with gzip.open(filename, "rb") as f:
        return pickle.load(f)

# Lista de nombres de las variables (ajustar seg√∫n el dataset)
feature_names = ["Temperatura", "Humedad", "Luz", "CO2"]

# Interfaz en Streamlit
st.subheader("Modelo planteado con XGBoost")

# Cargar modelo
model = load_model()

# Entrada manual de valores
st.subheader("Ingrese los valores para la predicci√≥n")
user_input = {}
for feature in feature_names:
    user_input[feature] = st.number_input(f"{feature}", value=0.0)

# Convertir entrada a array numpy
input_array = np.array(list(user_input.values())).reshape(1, -1)

# Bot√≥n de predicci√≥n
if st.button("Predecir"):
    prediction = model.predict(input_array)[0]
    resultado = "üü¢ Ocupado" if prediction == 1 else "üî¥ No Ocupado"
    st.subheader("Resultado de la Predicci√≥n")
    st.markdown(f"### {resultado}")

# Cargar modelo
modelo = cargar_modelo()

# Mostrar informaci√≥n sobre el modelo
st.subheader("üîç Informaci√≥n del modelo cargado")
st.write(f"Tipo de modelo: `{type(modelo)}`")

if hasattr(modelo, "summary"):  # Si es un modelo de Keras, mostrar estructura
    with st.expander("üìú Ver estructura del modelo"):
        st.text(modelo.summary())

# Secci√≥n de entrada interactiva
st.subheader("üìù Ingresa los valores para la predicci√≥n")

# Crear controles de entrada seg√∫n el modelo
if hasattr(modelo, "input_shape"):
    n_features = modelo.input_shape[1]  # N√∫mero de caracter√≠sticas esperadas
    entradas = []
    for i in range(n_features):
        valor = st.slider(f"üîπ Caracter√≠stica {i+1}", -10.0, 10.0, 0.0, step=0.1)
        entradas.append(valor)

    # Convertir a numpy array
    input_array = np.array(entradas).reshape(1, -1)

    # Realizar predicci√≥n
    if st.button("üîÆ Predecir"):
        prediccion = modelo.predict(input_array)[0][0]
        st.success(f"üìà Predicci√≥n del modelo: `{prediccion:.4f}`")

        # Graficar predicci√≥n
        fig, ax = plt.subplots()
        ax.bar(["Predicci√≥n"], [prediccion], color="royalblue")
        ax.set_ylabel("Valor de salida")
        ax.set_title("üìä Visualizaci√≥n de la Predicci√≥n")
        st.pyplot(fig)
else:
    st.error("‚ùå El modelo cargado no parece ser una red neuronal de Keras.")
